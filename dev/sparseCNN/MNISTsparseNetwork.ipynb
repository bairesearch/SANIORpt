{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgG8HHxG--qS"
      },
      "source": [
        "# MNIST Sparse Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kqyDzl0--qd"
      },
      "source": [
        "derived from https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHDn4fb3--qg"
      },
      "outputs": [],
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZiqCkU3--qi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.cluster.supervised import fowlkes_mallows_score\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")    #category=DeprecationWarning, message='is a deprecated alias'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "useSparseNetwork = True\n",
        "if(useSparseNetwork):    \n",
        "    paralleliseSparseProcessing = True   #parallel processing of sparse filters using Conv1d/Conv2d groups parameter\n",
        "    if(paralleliseSparseProcessing):\n",
        "        paralleliseSparseProcessingPrintTime = False\n",
        "        if(paralleliseSparseProcessingPrintTime):\n",
        "            start = torch.cuda.Event(enable_timing=True)\n",
        "            end = torch.cuda.Event(enable_timing=True)\n",
        "    \n",
        "    numberOfEpochsMLP = 1   #default: 10\n",
        "    numberOfEpochsCNN = 1   #default: 10\n",
        "    numberOfSparseLayersCNN = 2 #default: 1 (1 or 2)\n",
        "    numberOfSparseLayersMLP = 2 #default: 1 (1 or 2)\n",
        "    numberOfSublayerChannelsCNN = 2 #default: 2\n",
        "    numberOfSublayerChannelsMLP = 2 #default: 2\n",
        "else:\n",
        "    numberOfEpochsMLP = 10   #default: 20\n",
        "    numberOfEpochsCNN = 10   #default: 10\n",
        "    numberOfSparseLayersCNN = 1 #default: 1 #additional dense hidden layers\n",
        "    numberOfSparseLayersMLP = 1 #default: 0 #additional dense hidden layers\n",
        "\n",
        "#set Runtime type = high RAM\n",
        "#numberOfChannelsFirstDenseLayer: max value determined by numberOfSparseLayers, GPU RAM (independent of batchSize)\n",
        "\n",
        "#first/dense MLP layer;\n",
        "if(numberOfSparseLayersMLP == 0):\n",
        "    numberOfChannelsFirstDenseLayerMLP = 100\t#hidden_dim\n",
        "    batchSizeMLP = 1024 #128\n",
        "elif(numberOfSparseLayersMLP == 1):\n",
        "    numberOfChannelsFirstDenseLayerMLP = 100\n",
        "    batchSizeMLP = 1024 #128\n",
        "elif(numberOfSparseLayersMLP == 2):\n",
        "    numberOfChannelsFirstDenseLayerMLP = 20  #20 #2\n",
        "    batchSizeMLP = 1024 #128\n",
        "else:\n",
        "    print(\"useSparseNetwork warning: numberOfSparseLayersMLP is too high for compute/memory\")\n",
        "    numberOfChannelsFirstDenseLayerMLP = 2\n",
        "    batchSizeMLP = 16\n",
        "    \n",
        "#first/dense CNN layer;\n",
        "if(numberOfSparseLayersCNN == 0):\n",
        "    numberOfChannelsFirstDenseLayerCNN = 32\n",
        "    batchSizeCNN = 4096    #1024\n",
        "elif(numberOfSparseLayersCNN == 1):\n",
        "    numberOfChannelsFirstDenseLayerCNN = 32\n",
        "    batchSizeCNN = 4096    #1024\n",
        "elif(numberOfSparseLayersCNN == 2):\n",
        "    numberOfChannelsFirstDenseLayerCNN = 8  #8  #2\n",
        "    batchSizeCNN = 4096    #1024\n",
        "else:\n",
        "    print(\"useSparseNetwork warning: numberOfSparseLayersCNN is too high for compute/memory\")\n",
        "    numberOfChannelsFirstDenseLayerCNN = 2\n",
        "    batchSizeCNN = 16\n",
        "\n",
        "learningAlgorithmLUANN = False\n",
        "onlyTrainFinalLayer = False #initialise dependent var\n",
        "if(learningAlgorithmLUANN):\n",
        "    onlyTrainFinalLayer = True"
      ],
      "metadata": {
        "id": "KPtM4EX4eB0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sparse Layer Processing\n"
      ],
      "metadata": {
        "id": "n395XVMIzfhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseLayerProcessing():\n",
        "    def __init__(self, isCNNmodel, numberOfSublayerChannels, numberOfSparseLayers, layerDropout, numberOfChannelsFirstDenseLayer, kernelSize=None, padding=None, stride=None, maxPoolSize=None):\n",
        "\n",
        "        self.isCNNmodel = isCNNmodel\n",
        "\n",
        "        self.numberOfSublayerChannels = numberOfSublayerChannels\n",
        "        self.numberOfSparseLayers = numberOfSparseLayers\n",
        "        self.layerDropout = layerDropout\n",
        "        self.numberOfChannelsFirstDenseLayer = numberOfChannelsFirstDenseLayer\n",
        "        self.sparseLayerList = [None]*self.numberOfSparseLayers\n",
        "\n",
        "        if(isCNNmodel):\n",
        "            self.kernelSize = kernelSize\n",
        "            self.padding = padding\n",
        "            self.stride = stride\n",
        "            self.maxPoolSize = maxPoolSize\n",
        "\n",
        "    def generateSparseLayers(self, numberOfChannels, height=None, width=None):\n",
        "        for layerIndex in range(self.numberOfSparseLayers):\n",
        "            #print(\"layerIndex = \", layerIndex)\n",
        "            if(useSparseNetwork):\n",
        "                layer, numberOfChannels = self.generateSparseLayer(numberOfChannels)\n",
        "                self.sparseLayerList[layerIndex] = layer\n",
        "                if(self.isCNNmodel):\n",
        "                    height, width = self.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, self.maxPoolSize)\n",
        "            else:\n",
        "                #only used by CNN originally:\n",
        "                numberOfInputChannels = numberOfChannels\n",
        "                numberOfOutputChannels = numberOfChannels*2\n",
        "                layer = self.generateLayerStandard(numberOfChannels, numberOfOutputChannels)\n",
        "                self.sparseLayerList[layerIndex] = layer\n",
        "                numberOfChannels = numberOfOutputChannels\n",
        "                if(self.isCNNmodel):\n",
        "                    height, width = self.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, self.maxPoolSize)\n",
        "                \n",
        "        return numberOfChannels, height, width\n",
        "\n",
        "    def generateSparseLayer(self, numberOfChannels):\n",
        "        numChannelPairs = self.calculateNumberChannelPairs(numberOfChannels)\n",
        "        #print(\"numberOfChannels = \", numberOfChannels)\n",
        "        #print(\"numChannelPairs = \", numChannelPairs)\n",
        "        numberOfInputChannels = self.numberOfSublayerChannels\n",
        "        numberOfOutputChannels = 1\n",
        "        if(paralleliseSparseProcessing):\n",
        "            layer = self.generateSparseLayerParallel(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        else:\n",
        "            layer = self.generateSparseLayerStandard(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        numberOfChannels = numChannelPairs*numberOfOutputChannels\n",
        "        return layer, numberOfChannels\n",
        "    def generateSparseLayerStandard(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        sparseSublayerList = []\n",
        "        for channelPairIndex in range(numChannelPairs):\n",
        "            sublayer = self.generateLayerStandard(numberOfInputChannels, numberOfOutputChannels)\n",
        "            sparseSublayerList.append(sublayer)\n",
        "        return sparseSublayerList\n",
        "    def generateSparseLayerParallel(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        layer = self.generateLayerParallel(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        return layer\n",
        "\n",
        "    def generateLayerParallel(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.generateLayerParallelCNN(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        else:\n",
        "            return self.generateLayerParallelMLP(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "    def generateLayerParallelMLP(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        #https://stackoverflow.com/questions/58374980/run-multiple-models-of-an-ensemble-in-parallel-with-pytorch/58389075#58389075\n",
        "        layer = nn.Conv1d(numberOfInputChannels*numChannelPairs, numberOfOutputChannels*numChannelPairs, kernel_size=1, groups=numChannelPairs)\n",
        "        return layer\n",
        "    def generateLayerParallelCNN(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        conv2DnumberSubChannels = numberOfInputChannels*numChannelPairs\n",
        "        layer = nn.Conv2d(conv2DnumberSubChannels, conv2DnumberSubChannels, kernel_size=self.kernelSize, padding=self.padding, stride=self.stride, groups=conv2DnumberSubChannels)\n",
        "        return layer\n",
        "\n",
        "    def generateLayerStandard(self, numberOfInputChannels, numberOfOutputChannels):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.generateLayerStandardCNN(numberOfInputChannels, numberOfOutputChannels)\n",
        "        else:\n",
        "            return self.generateLayerStandardMLP(numberOfInputChannels, numberOfOutputChannels)\n",
        "    def generateLayerStandardMLP(self, numberOfInputChannels, numberOfOutputChannels):\n",
        "        layer = nn.Linear(numberOfInputChannels, numberOfOutputChannels)\n",
        "        return layer\n",
        "    def generateLayerStandardCNN(self, numberOfInputChannels, numberOfOutputChannels):\n",
        "        layer = nn.Conv2d(numberOfInputChannels, numberOfOutputChannels, kernel_size=self.kernelSize, padding=self.padding, stride=self.stride)\n",
        "        return layer\n",
        "\n",
        "    def executeSparseLayers(self, X):\n",
        "        numberOfChannels = self.numberOfChannelsFirstDenseLayer\n",
        "        for layerIndex in range(self.numberOfSparseLayers):\n",
        "            if(useSparseNetwork):\n",
        "                layerZ, numberOfChannels = self.executeSparseLayer(layerIndex, X, numberOfChannels)\n",
        "            else:\n",
        "                layerIn = X\n",
        "                layerZ = (self.sparseLayerList[layerIndex])(layerIn)\n",
        "            layerOut = self.activationFunction(layerZ)\n",
        "            X = layerOut\n",
        "        return X\n",
        "    \n",
        "    def executeSparseLayer(self, layerIndex, X, numberOfChannels):\n",
        "        numChannelPairs = self.calculateNumberChannelPairs(numberOfChannels)\n",
        "        numberOfInputChannels = self.numberOfSublayerChannels\n",
        "        numberOfOutputChannels = 1\n",
        "        channelsPairsList = []\n",
        "        self.convertToChannelsToChannelPairsList(X, 0, self.numberOfSublayerChannels, None, channelsPairsList, numberOfChannels)\n",
        "        if(paralleliseSparseProcessing):\n",
        "            layerZ = self.executeSparseLayerParallel(layerIndex, channelsPairsList, numChannelPairs)\n",
        "        else:\n",
        "            layerZ = self.executeSparseLayerStandard(layerIndex, channelsPairsList, numChannelPairs)\n",
        "        numberOfChannels = numChannelPairs*numberOfOutputChannels\n",
        "        return layerZ, numberOfChannels\n",
        "    def executeSparseLayerStandard(self, layerIndex, channelsPairsList, numChannelPairs):\n",
        "        channelPairSublayerOutputList = []\n",
        "        for channelPairIndex in range(numChannelPairs):\n",
        "            sublayerIn = channelsPairsList[channelPairIndex]\n",
        "            sublayerOut = (self.sparseLayerList[layerIndex])[channelPairIndex](sublayerIn)\n",
        "            sublayerOut = torch.squeeze(sublayerOut, dim=1)   #remove channel dim (size=numberOfOutputChannels=1); prepare for convertChannelPairLINoutputListToChannels execution\n",
        "            channelPairSublayerOutputList.append(sublayerOut)\n",
        "        layerZ = self.convertChannelPairSublayerOutputListToChannels(channelPairSublayerOutputList)\n",
        "        return layerZ\n",
        "    def executeSparseLayerParallel(self, layerIndex, channelsPairsList, numChannelPairs):\n",
        "        firstTensorInList = channelsPairsList[0]    #shape = [batchSize, numberOfInputChannels, ..]\n",
        "        print(\"executeSparseLayerParallel: layerIndex = \", layerIndex, \", firstTensorInList.shape = \", firstTensorInList.shape, \", numChannelPairs = \", numChannelPairs)\n",
        "        tensorPropertiesTuple = self.getSublayerTensorProperties(firstTensorInList)   #get properties from first tensor in list\n",
        "        #numChannelPairs = len(channelsPairsList)\n",
        "        channelsPairs = torch.stack(channelsPairsList, dim=1)   #shape = [batchSize, numChannelPairs, numberOfInputChannels, ..]\n",
        "        if(self.isCNNmodel):\n",
        "            if(paralleliseSparseProcessingPrintTime):\n",
        "                start.record()\n",
        "            (batchSize, numberOfInputChannels, height, width) = tensorPropertiesTuple\n",
        "            conv2DnumberSubChannels = numberOfInputChannels*numChannelPairs\n",
        "            layerIn = torch.reshape(channelsPairs, (batchSize, numChannelPairs*numberOfInputChannels, height, width))\n",
        "            layerZ = (self.sparseLayerList[layerIndex])(layerIn)  #channels convoluted separately (in separate groups)\n",
        "            height, width = self.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, 1)  #no max pool has been performed\n",
        "            layerZ = torch.reshape(layerZ, (batchSize, numChannelPairs, numberOfInputChannels, height, width))\n",
        "            layerZ = torch.sum(layerZ, dim=2)  #take sum of numberOfInputChannels (emulates element-wise sum as performed by CNN with groups=1)\n",
        "            if(paralleliseSparseProcessingPrintTime):\n",
        "                end.record()\n",
        "                torch.cuda.synchronize()\n",
        "                print(start.elapsed_time(end))\n",
        "        else:\n",
        "            (batchSize, numberOfInputChannels) = tensorPropertiesTuple\n",
        "            #https://stackoverflow.com/questions/58374980/run-multiple-models-of-an-ensemble-in-parallel-with-pytorch/58389075#58389075\n",
        "            layerIn = torch.reshape(channelsPairs, (batchSize, numChannelPairs*numberOfInputChannels, 1))\n",
        "            layerZ = (self.sparseLayerList[layerIndex])(layerIn)\n",
        "            layerZ = torch.reshape(layerZ, (batchSize, numChannelPairs))\n",
        "        print(\"executeSparseLayerParallel: layerZ.shape = \", layerZ.shape)\n",
        "        #layerZ shape = [batchSize, numChannelPairs, ..]\n",
        "        return layerZ\n",
        "\n",
        "    def activationFunction(self, Z, useDropOut=True):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.activationFunctionCNN(Z, useDropOut)\n",
        "        else:\n",
        "            return self.activationFunctionMLP(Z, useDropOut)\n",
        "    def activationFunctionMLP(self, Z, useDropOut=True):\n",
        "        A = F.relu(Z)\n",
        "        if(useDropOut):\n",
        "            A = self.layerDropout(A)\n",
        "        return A\n",
        "    def activationFunctionCNN(self, Z, useDropOut=True):\n",
        "        if(useDropOut):\n",
        "            Z = self.layerDropout(Z)\n",
        "        A = torch.relu(F.max_pool2d(Z, kernel_size=self.maxPoolSize))\n",
        "        return A\n",
        "\n",
        "    def calculateNumberChannelPairs(self, numInputChannels):\n",
        "        numChannelPairs = numInputChannels**self.numberOfSublayerChannels\n",
        "        return numChannelPairs\n",
        "        #numOutputChannels = number of filters\n",
        "\n",
        "    def convertToChannelsToChannelPairsList(self, channels, sublayerChannelIndex, numberOfSublayerChannels, channelPair, channelsPairsList, numberOfChannels):\n",
        "        if(sublayerChannelIndex == numberOfSublayerChannels):\n",
        "            channelsPairsList.append(channelPair)\n",
        "        else:\n",
        "            #numChannelPairs = self.calculateNumberChannelPairs(numberOfChannels)\n",
        "            for channelIndex in range(numberOfChannels):\n",
        "                #channelPairIndex = channelIndex1*numChannelPairs + channelIndex2\n",
        "                channelPairSub1 = channels[:, channelIndex]  #channels[:, channelIndex1, :]\n",
        "                channelPairSub1 = torch.unsqueeze(channelPairSub1, dim=1)\n",
        "                if(sublayerChannelIndex == 0):\n",
        "                    channelPair2 = channelPairSub1\n",
        "                else:\n",
        "                    channelPair2 = torch.clone(channelPair)\n",
        "                    channelPair2 = torch.cat((channelPair, channelPairSub1), dim=1)\n",
        "                self.convertToChannelsToChannelPairsList(channels, sublayerChannelIndex+1, numberOfSublayerChannels, channelPair2, channelsPairsList, numberOfChannels)\n",
        "\n",
        "    def getSublayerTensorProperties(self, channels):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.getCNNtensorProperties(channels)\n",
        "        else:\n",
        "            return self.getMLPtensorProperties(channels)\n",
        "    def getMLPtensorProperties(self, channels):\n",
        "        batchSize = channels.shape[0]\n",
        "        numberOfChannels = channels.shape[1]\n",
        "        tensorPropertiesTuple = (batchSize, numberOfChannels)\n",
        "        return tensorPropertiesTuple\n",
        "    def getCNNtensorProperties(self, channels):\n",
        "        batchSize = channels.shape[0]\n",
        "        numberOfChannels = channels.shape[1]\n",
        "        height = channels.shape[2]\n",
        "        width = channels.shape[3]\n",
        "        tensorPropertiesTuple = (batchSize, numberOfChannels, height, width)\n",
        "        return tensorPropertiesTuple\n",
        "\n",
        "    def convertChannelPairSublayerOutputListToChannels(self, channelPairSublayerOutputList):\n",
        "        layerZ = torch.stack(channelPairSublayerOutputList, dim=1)\n",
        "        return layerZ\n",
        "\n",
        "    def getImageDimensionsAfterConv(self, inputHeight, inputWidth, kernelSize, padding, stride, maxPoolSize):\n",
        "        height = (inputHeight - (kernelSize//2 * 2) + padding) // stride // maxPoolSize    #// = integer floor division\n",
        "        width = (inputWidth - (kernelSize//2 * 2) + padding) // stride // maxPoolSize\n",
        "        return height, width"
      ],
      "metadata": {
        "id": "GHaWEFCRzluS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse MLP Model"
      ],
      "metadata": {
        "id": "qEYtSRBIfloL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhsLIZfg--qk"
      },
      "source": [
        "## Load data (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHo3HR4P--qm"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK-oE30K--qn"
      },
      "outputs": [],
      "source": [
        "mnist.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWTDRrfA--qq"
      },
      "outputs": [],
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF6q-259--qt"
      },
      "outputs": [],
      "source": [
        "X /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk5cZ7iQ--qv"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpeDtsDy--qw"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OmjGef_--qz"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33lwxpxN--qz"
      },
      "outputs": [],
      "source": [
        "mnist_dim = X.shape[1]\n",
        "hidden_dim = int(mnist_dim/8)\n",
        "output_dim = len(np.unique(mnist.target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mHnjijo--q0"
      },
      "source": [
        "## Define model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC311xvO--q0"
      },
      "outputs": [],
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_dim=mnist_dim, hidden_dim=hidden_dim, output_dim=output_dim, dropout=0.5):\n",
        "        super(MLPModel, self).__init__()\n",
        "\n",
        "        self.isCNNmodel = False\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        #print(\"hidden_dim = \", hidden_dim)\n",
        "        self.numberOfSparseLayers = numberOfSparseLayersMLP   #default: 1 (1 or 2)\n",
        "        self.numberOfChannelsFirstDenseLayer = numberOfChannelsFirstDenseLayerMLP\n",
        "\n",
        "        numberOfChannels = self.numberOfChannelsFirstDenseLayer \n",
        "\n",
        "        self.linear1 = nn.Linear(input_dim, numberOfChannels)  #first/dense linear layer \n",
        "\n",
        "        self.sparseLayerProcessing = SparseLayerProcessing(self.isCNNmodel, numberOfSublayerChannelsMLP, self.numberOfSparseLayers, self.dropout, self.numberOfChannelsFirstDenseLayer)\n",
        "\n",
        "        numberOfChannels, _, _ = self.sparseLayerProcessing.generateSparseLayers(numberOfChannels)\n",
        "\n",
        "        self.output = nn.Linear(numberOfChannels, output_dim)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "\n",
        "        #first/dense linear layer\n",
        "        x = self.linear1(x)\n",
        "        x = self.sparseLayerProcessing.activationFunction(x)\n",
        "\n",
        "        x = self.sparseLayerProcessing.executeSparseLayers(x)\n",
        "\n",
        "        if(onlyTrainFinalLayer):\n",
        "            x = x.detach()\n",
        "\n",
        "        x = F.softmax(self.output(x), dim=-1)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model (MLP)"
      ],
      "metadata": {
        "id": "rDx0f8NSeLR1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AicBGdq0--q1"
      },
      "outputs": [],
      "source": [
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBYpucG0--q2"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    MLPModel,\n",
        "    max_epochs=numberOfEpochsMLP,\n",
        "    lr=0.1,\n",
        "    device=device,\n",
        "    batch_size=batchSizeMLP,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfUx7jMR--q2"
      },
      "outputs": [],
      "source": [
        "net.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjgE-Uto--q2"
      },
      "source": [
        "## Evaluate model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJMblY39--q3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLD7E8KR--q3"
      },
      "outputs": [],
      "source": [
        "y_pred = net.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dCUHN_p--q3"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse CNN Model"
      ],
      "metadata": {
        "id": "OgIUkrq9fdLr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ9yogDR--q5"
      },
      "source": [
        "## Load data (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "446TDdHV--q5"
      },
      "outputs": [],
      "source": [
        "XCnn = X.reshape(-1, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kwClR2Q--q6"
      },
      "outputs": [],
      "source": [
        "XCnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgYFsGJ7--q6"
      },
      "outputs": [],
      "source": [
        "XCnn_train, XCnn_test, y_train, y_test = train_test_split(XCnn, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNJJXx4h--q6"
      },
      "outputs": [],
      "source": [
        "XCnn_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model (CNN)"
      ],
      "metadata": {
        "id": "p84VQQrefOii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXnsFnJf--q7"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.isCNNmodel = True\n",
        "\n",
        "        height = 28 #MNIST defined\n",
        "        width = 28  #MNIST defined\n",
        "        self.kernelSize = 3\n",
        "        self.padding = 0\n",
        "        self.stride = 1\n",
        "        self.maxPoolSize = 2 #assume max pool at each layer\n",
        "\n",
        "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
        "\n",
        "        self.numberOfSparseLayers = numberOfSparseLayersCNN #default: 1 (1 or 2)\n",
        "        self.numberOfChannelsFirstDenseLayer = numberOfChannelsFirstDenseLayerCNN\n",
        "\n",
        "        numberOfChannels = self.numberOfChannelsFirstDenseLayer  \n",
        "        self.conv1 = nn.Conv2d(1, numberOfChannels, kernel_size=self.kernelSize, padding=self.padding, stride=self.stride)  #first/dense linear layer\n",
        "\n",
        "        self.sparseLayerProcessing = SparseLayerProcessing(self.isCNNmodel, numberOfSublayerChannelsCNN, self.numberOfSparseLayers, self.conv2_drop, self.numberOfChannelsFirstDenseLayer, kernelSize=self.kernelSize, padding=self.padding, stride=self.stride, maxPoolSize=self.maxPoolSize)\n",
        "        \n",
        "        height, width = self.sparseLayerProcessing.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, self.maxPoolSize)\n",
        "        numberOfChannels, width, height = self.sparseLayerProcessing.generateSparseLayers(numberOfChannels, height, width)\n",
        "\n",
        "        firstLinearInputSize = numberOfChannels*width*height\n",
        "\n",
        "        self.fc1 = nn.Linear(firstLinearInputSize, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc1_drop = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.sparseLayerProcessing.activationFunction(x, useDropOut=False)\n",
        "\n",
        "        x = self.sparseLayerProcessing.executeSparseLayers(x)\n",
        "\n",
        "        if(onlyTrainFinalLayer):\n",
        "            x = x.detach()\n",
        "\n",
        "        # flatten over channel, height and width\n",
        "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "\n",
        "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
        "        x = torch.softmax(self.fc2(x), dim=-1)\n",
        "\n",
        "        return x\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model (CNN)"
      ],
      "metadata": {
        "id": "He_2hz_OfVA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs3_lkRZ--q7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "cnn = NeuralNetClassifier(\n",
        "    CNNModel,\n",
        "    max_epochs=numberOfEpochsCNN,\n",
        "    lr=0.002,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    device=device,\n",
        "    batch_size=batchSizeCNN,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UykGA1k_--q7"
      },
      "outputs": [],
      "source": [
        "cnn.fit(XCnn_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model (CNN)"
      ],
      "metadata": {
        "id": "ufleB4dFfYbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNEhdJdW--q8"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn = cnn.predict(XCnn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szmTFII6--q8"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred_cnn)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}