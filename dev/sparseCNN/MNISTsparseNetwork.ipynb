{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgG8HHxG--qS"
      },
      "source": [
        "# Sparse Network: MNIST with SciKit-Learn and skorch\n",
        "\n",
        "This notebooks shows how to define and train a simple Neural-Network with PyTorch and use it via skorch with SciKit-Learn.\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kqyDzl0--qd"
      },
      "source": [
        "**Note**: If you are running this in [a colab notebook](https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb), we recommend you enable a free GPU by going:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
        "\n",
        "If you are running in colab, you should install the dependencies and download the dataset by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tHDn4fb3--qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a100e09-e67a-4dda-dd0c-2b99b7507c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: scikit-learn==0.20.* in /usr/local/lib/python3.7/dist-packages (0.20.4)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.20.*) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.20.*) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.64.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.10)\n"
          ]
        }
      ],
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VZiqCkU3--qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ce2275-0f7f-475c-d12c-407fd0e026fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype=np.int):\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.cluster.supervised import fowlkes_mallows_score\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")    #category=DeprecationWarning, message='is a deprecated alias'\n",
        "\n",
        "useSparseNetwork = True\n",
        "if(useSparseNetwork):\n",
        "    paralleliseSparseProcessing = True   #parallel processing of sparse filters using Conv1d/Conv2d groups parameter\n",
        "    if(paralleliseSparseProcessing):\n",
        "        paralleliseSparseProcessingPrintTime = False\n",
        "        if(paralleliseSparseProcessingPrintTime):\n",
        "            start = torch.cuda.Event(enable_timing=True)\n",
        "            end = torch.cuda.Event(enable_timing=True)\n",
        "    \n",
        "    numberOfEpochsMLP = 1   #default: 10\n",
        "    numberOfEpochsCNN = 1   #default: 10\n",
        "    numberOfSparseLayersCNN = 2 #default: 1 (1 or 2)\n",
        "    numberOfSparseLayersMLP = 2 #default: 1 (1 or 2)\n",
        "else:\n",
        "    numberOfEpochsMLP = 1   #default: 20\n",
        "    numberOfEpochsCNN = 1   #default: 10\n",
        "    numberOfSparseLayersCNN = 1 #default: 1 #additional dense hidden layers\n",
        "    numberOfSparseLayersMLP = 1 #default: 0 #additional dense hidden layers\n",
        "\n",
        "#set Runtime type = high RAM\n",
        "#numberOfchannelsFirstDenseLayer: max value determined by numberOfSparseLayers, GPU RAM (independent of batchSize)\n",
        "\n",
        "#first/dense MLP layer;\n",
        "if(numberOfSparseLayersMLP == 0):\n",
        "    numberOfchannelsFirstDenseLayerMLP = 100\t#hidden_dim\n",
        "    batchSizeMLP = 1024 #128\n",
        "elif(numberOfSparseLayersMLP == 1):\n",
        "    numberOfchannelsFirstDenseLayerMLP = 100\n",
        "    batchSizeMLP = 1024 #128\n",
        "elif(numberOfSparseLayersMLP == 2):\n",
        "    numberOfchannelsFirstDenseLayerMLP = 20 #2\n",
        "    batchSizeMLP = 1024 #128\n",
        "else:\n",
        "    print(\"useSparseNetwork warning: numberOfSparseLayersMLP is too high for compute/memory\")\n",
        "    numberOfchannelsFirstDenseLayerMLP = 2\n",
        "    batchSizeMLP = 16\n",
        "    \n",
        "#first/dense CNN layer;\n",
        "if(numberOfSparseLayersCNN == 0):\n",
        "    numberOfchannelsFirstDenseLayerCNN = 32\n",
        "    batchSizeCNN = 4096    #1024\n",
        "elif(numberOfSparseLayersCNN == 1):\n",
        "    numberOfchannelsFirstDenseLayerCNN = 32\n",
        "    batchSizeCNN = 4096    #1024\n",
        "elif(numberOfSparseLayersCNN == 2):\n",
        "    numberOfchannelsFirstDenseLayerCNN = 8\n",
        "    batchSizeCNN = 4096    #1024\n",
        "else:\n",
        "    print(\"useSparseNetwork warning: numberOfSparseLayersCNN is too high for compute/memory\")\n",
        "    numberOfchannelsFirstDenseLayerCNN = 2\n",
        "    batchSizeCNN = 16\n",
        "\n",
        "learningAlgorithmLUANN = False\n",
        "onlyTrainFinalLayer = False #initialise dependent var\n",
        "if(learningAlgorithmLUANN):\n",
        "    onlyTrainFinalLayer = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sparse Layer Processing\n"
      ],
      "metadata": {
        "id": "n395XVMIzfhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseLayerProcessing():\n",
        "    def __init__(self, isCNNmodel, numberOfSparseLayers, layerDropout, numberOfchannelsFirstDenseLayer, kernelSize=None, padding=None, stride=None, maxPoolSize=None):\n",
        "\n",
        "        self.isCNNmodel = isCNNmodel\n",
        "\n",
        "        self.numberOfSparseLayers = numberOfSparseLayers\n",
        "        self.layerDropout = layerDropout\n",
        "        self.numberOfchannelsFirstDenseLayer = numberOfchannelsFirstDenseLayer\n",
        "        self.sparseLayerList = [None]*self.numberOfSparseLayers\n",
        "\n",
        "        if(isCNNmodel):\n",
        "            self.kernelSize = kernelSize\n",
        "            self.padding = padding\n",
        "            self.stride = stride\n",
        "            self.maxPoolSize = maxPoolSize\n",
        "\n",
        "    def generateSparseLayers(self, numberOfchannels, height=None, width=None):\n",
        "        for layerIndex in range(self.numberOfSparseLayers):\n",
        "            #print(\"layerIndex = \", layerIndex)\n",
        "            if(useSparseNetwork):\n",
        "                layer, numberOfchannels = self.generateSparseLayer(numberOfchannels)\n",
        "                self.sparseLayerList[layerIndex] = layer\n",
        "                if(self.isCNNmodel):\n",
        "                    height, width = self.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, self.maxPoolSize)\n",
        "            else:\n",
        "                #only used by CNN originally:\n",
        "                numberOfInputChannels = numberOfchannels\n",
        "                numberOfOutputChannels = numberOfchannels*2\n",
        "                layer = self.generateLayerStandard(numberOfchannels, numberOfOutputChannels)\n",
        "                self.sparseLayerList[layerIndex] = layer\n",
        "                numberOfchannels = numberOfOutputChannels\n",
        "                if(self.isCNNmodel):\n",
        "                    height, width = self.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, self.maxPoolSize)\n",
        "                \n",
        "        return numberOfchannels, height, width\n",
        "\n",
        "    def generateSparseLayer(self, numberOfchannels):\n",
        "        numChannelPairs = self.calculateNumberChannelPairs(numberOfchannels)\n",
        "        #print(\"numberOfchannels = \", numberOfchannels)\n",
        "        #print(\"numChannelPairs = \", numChannelPairs)\n",
        "        numberOfInputChannels = 2\n",
        "        numberOfOutputChannels = 1\n",
        "        if(paralleliseSparseProcessing):\n",
        "            layer = self.generateSparseLayerParallel(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        else:\n",
        "            layer = self.generateSparseLayerStandard(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        numberOfchannels = numChannelPairs*numberOfOutputChannels\n",
        "        return layer, numberOfchannels\n",
        "    def generateSparseLayerStandard(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        sparseSublayerList = []\n",
        "        for channelPairIndex in range(numChannelPairs):\n",
        "            sublayer = self.generateLayerStandard(numberOfInputChannels, numberOfOutputChannels)\n",
        "            sparseSublayerList.append(sublayer)\n",
        "        return sparseSublayerList\n",
        "    def generateSparseLayerParallel(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        layer = self.generateLayerParallel(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        return layer\n",
        "\n",
        "    def generateLayerParallel(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.generateLayerParallelCNN(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "        else:\n",
        "            return self.generateLayerParallelMLP(numChannelPairs, numberOfInputChannels, numberOfOutputChannels)\n",
        "    def generateLayerParallelMLP(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        #https://stackoverflow.com/questions/58374980/run-multiple-models-of-an-ensemble-in-parallel-with-pytorch/58389075#58389075\n",
        "        layer = nn.Conv1d(numberOfInputChannels*numChannelPairs, numberOfOutputChannels*numChannelPairs, kernel_size=1, groups=numChannelPairs)\n",
        "        return layer\n",
        "    def generateLayerParallelCNN(self, numChannelPairs, numberOfInputChannels, numberOfOutputChannels):\n",
        "        conv2DnumberSubChannels = numberOfInputChannels*numChannelPairs\n",
        "        layer = nn.Conv2d(conv2DnumberSubChannels, conv2DnumberSubChannels, kernel_size=self.kernelSize, padding=self.padding, stride=self.stride, groups=conv2DnumberSubChannels)\n",
        "        return layer\n",
        "\n",
        "    def generateLayerStandard(self, numberOfInputChannels, numberOfOutputChannels):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.generateLayerStandardCNN(numberOfInputChannels, numberOfOutputChannels)\n",
        "        else:\n",
        "            return self.generateLayerStandardMLP(numberOfInputChannels, numberOfOutputChannels)\n",
        "    def generateLayerStandardMLP(self, numberOfInputChannels, numberOfOutputChannels):\n",
        "        layer = nn.Linear(numberOfInputChannels, numberOfOutputChannels)\n",
        "        return layer\n",
        "    def generateLayerStandardCNN(self, numberOfInputChannels, numberOfOutputChannels):\n",
        "        layer = nn.Conv2d(numberOfInputChannels, numberOfOutputChannels, kernel_size=self.kernelSize, padding=self.padding, stride=self.stride)\n",
        "        return layer\n",
        "\n",
        "    def executeSparseLayers(self, X):\n",
        "        numberOfchannels = self.numberOfchannelsFirstDenseLayer\n",
        "        for layerIndex in range(self.numberOfSparseLayers):\n",
        "            if(useSparseNetwork):\n",
        "                layerZ, numberOfchannels = self.executeSparseLayer(layerIndex, X, numberOfchannels)\n",
        "            else:\n",
        "                layerIn = X\n",
        "                layerZ = (self.sparseLayerList[layerIndex])(layerIn)\n",
        "            layerOut = self.activationFunction(layerZ)\n",
        "            X = layerOut\n",
        "        return X\n",
        "    \n",
        "    def executeSparseLayer(self, layerIndex, X, numberOfchannels):\n",
        "        numChannelPairs = self.calculateNumberChannelPairs(numberOfchannels)\n",
        "        numberOfInputChannels = 2\n",
        "        numberOfOutputChannels = 1\n",
        "        channelsPairsList = self.convertToChannelsToChannelPairsList(X)\n",
        "        if(paralleliseSparseProcessing):\n",
        "            layerZ = self.executeSparseLayerParallel(layerIndex, channelsPairsList, numChannelPairs)\n",
        "        else:\n",
        "            layerZ = self.executeSparseLayerStandard(layerIndex, channelsPairsList, numChannelPairs)\n",
        "        numberOfchannels = numChannelPairs*numberOfOutputChannels\n",
        "        return layerZ, numberOfchannels\n",
        "    def executeSparseLayerStandard(self, layerIndex, channelsPairsList, numChannelPairs):\n",
        "        channelPairSublayerOutputList = []\n",
        "        for channelPairIndex in range(numChannelPairs):\n",
        "            sublayerIn = channelsPairsList[channelPairIndex]\n",
        "            sublayerOut = (self.sparseLayerList[layerIndex])[channelPairIndex](sublayerIn)\n",
        "            sublayerOut = torch.squeeze(sublayerOut, dim=1)   #remove channel dim (size=numberOfOutputChannels=1); prepare for convertChannelPairLINoutputListToChannels execution\n",
        "            channelPairSublayerOutputList.append(sublayerOut)\n",
        "        layerZ = self.convertChannelPairSublayerOutputListToChannels(channelPairSublayerOutputList)\n",
        "        return layerZ\n",
        "    def executeSparseLayerParallel(self, layerIndex, channelsPairsList, numChannelPairs):\n",
        "        firstTensorInList = channelsPairsList[0]    #shape = [batchSize, numberOfInputChannels, ..]\n",
        "        print(\"executeSparseLayerParallel: layerIndex = \", layerIndex, \", firstTensorInList.shape = \", firstTensorInList.shape, \", numChannelPairs = \", numChannelPairs)\n",
        "        tensorPropertiesTuple = self.getSublayerTensorProperties(firstTensorInList)   #get properties from first tensor in list\n",
        "        #numChannelPairs = len(channelsPairsList)\n",
        "        channelsPairs = torch.stack(channelsPairsList, dim=1)   #shape = [batchSize, numChannelPairs, numberOfInputChannels, ..]\n",
        "        if(self.isCNNmodel):\n",
        "            if(paralleliseSparseProcessingPrintTime):\n",
        "                start.record()\n",
        "            (batchSize, numberOfInputChannels, height, width) = tensorPropertiesTuple\n",
        "            conv2DnumberSubChannels = numberOfInputChannels*numChannelPairs\n",
        "            layerIn = torch.reshape(channelsPairs, (batchSize, numChannelPairs*numberOfInputChannels, height, width))\n",
        "            layerZ = (self.sparseLayerList[layerIndex])(layerIn)  #channels convoluted separately (in separate groups)\n",
        "            height, width = self.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, 1)  #no max pool has been performed\n",
        "            layerZ = torch.reshape(layerZ, (batchSize, numChannelPairs, numberOfInputChannels, height, width))\n",
        "            layerZ = torch.sum(layerZ, dim=2)  #take sum of numberOfInputChannels (emulates element-wise sum as performed by CNN with groups=1)\n",
        "            if(paralleliseSparseProcessingPrintTime):\n",
        "                end.record()\n",
        "                torch.cuda.synchronize()\n",
        "                print(start.elapsed_time(end))\n",
        "        else:\n",
        "            (batchSize, numberOfInputChannels) = tensorPropertiesTuple\n",
        "            #https://stackoverflow.com/questions/58374980/run-multiple-models-of-an-ensemble-in-parallel-with-pytorch/58389075#58389075\n",
        "            layerIn = torch.reshape(channelsPairs, (batchSize, numChannelPairs*numberOfInputChannels, 1))\n",
        "            layerZ = (self.sparseLayerList[layerIndex])(layerIn)\n",
        "            layerZ = torch.reshape(layerZ, (batchSize, numChannelPairs))\n",
        "        print(\"executeSparseLayerParallel: layerZ.shape = \", layerZ.shape)\n",
        "        #layerZ shape = [batchSize, numChannelPairs, ..]\n",
        "        return layerZ\n",
        "\n",
        "    def activationFunction(self, Z, useDropOut=True):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.activationFunctionCNN(Z, useDropOut)\n",
        "        else:\n",
        "            return self.activationFunctionMLP(Z, useDropOut)\n",
        "    def activationFunctionMLP(self, Z, useDropOut=True):\n",
        "        A = F.relu(Z)\n",
        "        if(useDropOut):\n",
        "            A = self.layerDropout(A)\n",
        "        return A\n",
        "    def activationFunctionCNN(self, Z, useDropOut=True):\n",
        "        if(useDropOut):\n",
        "            Z = self.layerDropout(Z)\n",
        "        A = torch.relu(F.max_pool2d(Z, kernel_size=self.maxPoolSize))\n",
        "        return A\n",
        "\n",
        "    def calculateNumberChannelPairs(self, numInputChannels):\n",
        "        numChannelPairs = numInputChannels**2\n",
        "        return numChannelPairs\n",
        "        #numOutputChannels = number of filters\n",
        "\n",
        "    def convertToChannelsToChannelPairsList(self, channels):\n",
        "        tensorPropertiesTuple = self.getSublayerTensorProperties(channels)\n",
        "        batchSize = tensorPropertiesTuple[0]\n",
        "        numberOfchannels = tensorPropertiesTuple[1]\n",
        "        numChannelPairs = self.calculateNumberChannelPairs(numberOfchannels)\n",
        "        channelsPairsList = []\n",
        "        for channelIndex1 in range(numberOfchannels):\n",
        "            for channelIndex2 in range(numberOfchannels):\n",
        "                channelPairIndex = channelIndex1*numChannelPairs + channelIndex2\n",
        "                channelPairSub1 = channels[:, channelIndex1]  #channels[:, channelIndex1, :]\n",
        "                channelPairSub2 = channels[:, channelIndex2]  #channels[:, channelIndex2, :]\n",
        "                channelPairSub1 = torch.unsqueeze(channelPairSub1, dim=1)\n",
        "                channelPairSub2 = torch.unsqueeze(channelPairSub2, dim=1)\n",
        "                channelPair = torch.cat((channelPairSub1, channelPairSub2), dim=1)\n",
        "                channelsPairsList.append(channelPair)\n",
        "        return channelsPairsList\n",
        "\n",
        "    def getSublayerTensorProperties(self, channels):\n",
        "        if(self.isCNNmodel):\n",
        "            return self.getCNNtensorProperties(channels)\n",
        "        else:\n",
        "            return self.getMLPtensorProperties(channels)\n",
        "    def getMLPtensorProperties(self, channels):\n",
        "        batchSize = channels.shape[0]\n",
        "        numberOfchannels = channels.shape[1]\n",
        "        tensorPropertiesTuple = (batchSize, numberOfchannels)\n",
        "        return tensorPropertiesTuple\n",
        "    def getCNNtensorProperties(self, channels):\n",
        "        batchSize = channels.shape[0]\n",
        "        numberOfchannels = channels.shape[1]\n",
        "        height = channels.shape[2]\n",
        "        width = channels.shape[3]\n",
        "        tensorPropertiesTuple = (batchSize, numberOfchannels, height, width)\n",
        "        return tensorPropertiesTuple\n",
        "\n",
        "    def convertChannelPairSublayerOutputListToChannels(self, channelPairSublayerOutputList):\n",
        "        layerZ = torch.stack(channelPairSublayerOutputList, dim=1)\n",
        "        return layerZ\n",
        "\n",
        "    def getImageDimensionsAfterConv(self, inputHeight, inputWidth, kernelSize, padding, stride, maxPoolSize):\n",
        "        height = (inputHeight - (kernelSize//2 * 2) + padding) // stride // maxPoolSize    #// = integer floor division\n",
        "        width = (inputWidth - (kernelSize//2 * 2) + padding) // stride // maxPoolSize\n",
        "        return height, width"
      ],
      "metadata": {
        "id": "GHaWEFCRzluS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhsLIZfg--qk"
      },
      "source": [
        "## Loading Data\n",
        "Using SciKit-Learns ```fetch_openml``` to load MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OHo3HR4P--qm"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yK-oE30K--qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f440ea-1e61-4c5f-88e5-cce1d6b9a78f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mnist.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBecc6yQ--qp"
      },
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
        "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hWTDRrfA--qq"
      },
      "outputs": [],
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBMFueA9--qs"
      },
      "source": [
        "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BF6q-259--qt"
      },
      "outputs": [],
      "source": [
        "X /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3gkoxPMQ--qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5725edc0-b703-44e0-c49b-4866f128a551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X.min(), X.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOgDy8AC--qu"
      },
      "source": [
        "Note: data is not normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Uk5cZ7iQ--qv"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JdzB7Jnn--qw"
      },
      "outputs": [],
      "source": [
        "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BpeDtsDy--qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5edc24-23e6-448b-8a45-18e44206be14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((52500, 784), (52500,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_EJvc00--qx"
      },
      "source": [
        "### Print a selection of training images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z3urGwj5--qx"
      },
      "outputs": [],
      "source": [
        "def plot_example(X, y):\n",
        "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
        "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
        "        plt.subplot(151 + i)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WCLy7ZXl--qy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "cbb2a80b-4477-47c7-e8d5-986cd1dbaf1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_example(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lOkB3Dm--qy"
      },
      "source": [
        "## Build Neural Network with PyTorch\n",
        "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8YysBfKi--qy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3OmjGef_--qz"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "33lwxpxN--qz"
      },
      "outputs": [],
      "source": [
        "mnist_dim = X.shape[1]\n",
        "hidden_dim = int(mnist_dim/8)\n",
        "output_dim = len(np.unique(mnist.target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0Dr2f4g9--q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad551c44-b874-48cf-9157-22420e202cd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 98, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "mnist_dim, hidden_dim, output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mHnjijo--q0"
      },
      "source": [
        "A Neural network in PyTorch's framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uC311xvO--q0"
      },
      "outputs": [],
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_dim=mnist_dim, hidden_dim=hidden_dim, output_dim=output_dim, dropout=0.5):\n",
        "        super(MLPModel, self).__init__()\n",
        "\n",
        "        self.isCNNmodel = False\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        #print(\"hidden_dim = \", hidden_dim)\n",
        "        self.numberOfSparseLayers = numberOfSparseLayersMLP   #default: 1 (1 or 2)\n",
        "        self.numberOfchannelsFirstDenseLayer = numberOfchannelsFirstDenseLayerMLP\n",
        "\n",
        "        numberOfchannels = self.numberOfchannelsFirstDenseLayer \n",
        "\n",
        "        self.linear1 = nn.Linear(input_dim, numberOfchannels)  #first/dense linear layer \n",
        "\n",
        "        self.sparseLayerProcessing = SparseLayerProcessing(self.isCNNmodel, self.numberOfSparseLayers, self.dropout, self.numberOfchannelsFirstDenseLayer)\n",
        "\n",
        "        numberOfchannels, _, _ = self.sparseLayerProcessing.generateSparseLayers(numberOfchannels)\n",
        "\n",
        "        self.output = nn.Linear(numberOfchannels, output_dim)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "\n",
        "        #first/dense linear layer\n",
        "        x = self.linear1(x)\n",
        "        x = self.sparseLayerProcessing.activationFunction(x)\n",
        "\n",
        "        x = self.sparseLayerProcessing.executeSparseLayers(x)\n",
        "\n",
        "        if(onlyTrainFinalLayer):\n",
        "            x = x.detach()\n",
        "\n",
        "        x = F.softmax(self.output(x), dim=-1)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-30HWZ-g--q1"
      },
      "source": [
        "skorch allows to use PyTorch's networks in the SciKit-Learn setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AicBGdq0--q1"
      },
      "outputs": [],
      "source": [
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uBYpucG0--q2"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    MLPModel,\n",
        "    max_epochs=numberOfEpochsMLP,\n",
        "    lr=0.1,\n",
        "    device=device,\n",
        "    batch_size=batchSizeMLP,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfUx7jMR--q2"
      },
      "outputs": [],
      "source": [
        "net.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjgE-Uto--q2"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QJMblY39--q3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLD7E8KR--q3"
      },
      "outputs": [],
      "source": [
        "y_pred = net.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dCUHN_p--q3"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXLcdqbN--q4"
      },
      "source": [
        "An accuracy of about 96% for a network with only one hidden layer is not too bad.\n",
        "\n",
        "Let's take a look at some predictions that went wrong:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tin-L-ui--q4"
      },
      "outputs": [],
      "source": [
        "error_mask = y_pred != y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmRLxBgM--q4"
      },
      "outputs": [],
      "source": [
        "plot_example(X_test[error_mask], y_pred[error_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ9yogDR--q5"
      },
      "source": [
        "# Convolutional Network\n",
        "PyTorch expects a 4 dimensional tensor as input for its 2D convolution layer. The dimensions represent:\n",
        "* Batch size\n",
        "* Number of channel\n",
        "* Height\n",
        "* Width\n",
        "\n",
        "As initial batch size the number of examples needs to be provided. MNIST data has only one channel. As stated above, each MNIST vector represents a 28x28 pixel image. Hence, the resulting shape for PyTorch tensor needs to be (x, 1, 28, 28). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "446TDdHV--q5"
      },
      "outputs": [],
      "source": [
        "XCnn = X.reshape(-1, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kwClR2Q--q6"
      },
      "outputs": [],
      "source": [
        "XCnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgYFsGJ7--q6"
      },
      "outputs": [],
      "source": [
        "XCnn_train, XCnn_test, y_train, y_test = train_test_split(XCnn, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNJJXx4h--q6"
      },
      "outputs": [],
      "source": [
        "XCnn_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXnsFnJf--q7"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.isCNNmodel = True\n",
        "\n",
        "        height = 28 #MNIST defined\n",
        "        width = 28  #MNIST defined\n",
        "        self.kernelSize = 3\n",
        "        self.padding = 0\n",
        "        self.stride = 1\n",
        "        self.maxPoolSize = 2 #assume max pool at each layer\n",
        "\n",
        "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
        "\n",
        "        self.numberOfSparseLayers = numberOfSparseLayersCNN #default: 1 (1 or 2)\n",
        "        self.numberOfchannelsFirstDenseLayer = numberOfchannelsFirstDenseLayerCNN\n",
        "\n",
        "        numberOfchannels = self.numberOfchannelsFirstDenseLayer  \n",
        "        self.conv1 = nn.Conv2d(1, numberOfchannels, kernel_size=self.kernelSize, padding=self.padding, stride=self.stride)  #first/dense linear layer\n",
        "\n",
        "        self.sparseLayerProcessing = SparseLayerProcessing(self.isCNNmodel, self.numberOfSparseLayers, self.conv2_drop, self.numberOfchannelsFirstDenseLayer, kernelSize=self.kernelSize, padding=self.padding, stride=self.stride, maxPoolSize=self.maxPoolSize)\n",
        "        \n",
        "        height, width = self.sparseLayerProcessing.getImageDimensionsAfterConv(height, width, self.kernelSize, self.padding, self.stride, self.maxPoolSize)\n",
        "        numberOfchannels, width, height = self.sparseLayerProcessing.generateSparseLayers(numberOfchannels, height, width)\n",
        "\n",
        "        firstLinearInputSize = numberOfchannels*width*height\n",
        "\n",
        "        self.fc1 = nn.Linear(firstLinearInputSize, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc1_drop = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.sparseLayerProcessing.activationFunction(x, useDropOut=False)\n",
        "\n",
        "        x = self.sparseLayerProcessing.executeSparseLayers(x)\n",
        "\n",
        "        if(onlyTrainFinalLayer):\n",
        "            x = x.detach()\n",
        "\n",
        "        # flatten over channel, height and width\n",
        "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "\n",
        "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
        "        x = torch.softmax(self.fc2(x), dim=-1)\n",
        "\n",
        "        return x\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs3_lkRZ--q7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "cnn = NeuralNetClassifier(\n",
        "    CNNModel,\n",
        "    max_epochs=numberOfEpochsCNN,\n",
        "    lr=0.002,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    device=device,\n",
        "    batch_size=batchSizeCNN,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UykGA1k_--q7"
      },
      "outputs": [],
      "source": [
        "cnn.fit(XCnn_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNEhdJdW--q8"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn = cnn.predict(XCnn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szmTFII6--q8"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KncVCQ7j--q9"
      },
      "source": [
        "An accuracy of >98% should suffice for this example!\n",
        "\n",
        "Let's see how we fare on the examples that went wrong before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ACEkdhG--q9"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test[error_mask], y_pred_cnn[error_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J83N6ubG--q9"
      },
      "source": [
        "Over 70% of the previously misclassified images are now correctly identified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl1Jz5bg--q-"
      },
      "outputs": [],
      "source": [
        "plot_example(X_test[error_mask], y_pred_cnn[error_mask])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}